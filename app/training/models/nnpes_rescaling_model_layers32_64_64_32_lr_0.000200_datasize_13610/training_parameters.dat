Seed: 42
Layer sizes: [32, 64, 64, 32]
Learning rate: 0.000200
Weight decay: 0.000000
Training data set size: 13610
Total epochs: 10000
Batch size: 64
Batch normalization applied: False
The transformations used are the following:

ReciprocalTransformer()

StandardizeTransformer(init_pair=(0.0, 0.45454545454545453), final_pair=(0.0, 1.0), linear_func=<function StandardizeTransformer.__post_init__.<locals>.map_init_pair_to_final_pair at 0x7f139497eaf0>)

MinimumPermutationTransformer(less_than_comparator=LessThanEpsilon(epsilon=0.0001))

Other information:
_rescaling_model_filtered11
